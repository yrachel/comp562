{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data\n",
    "docs = ['Where are you REALLY from?',\n",
    "       'Go back to where you came from!',\n",
    "       'What\\'s my Chinese name?',\n",
    "       'Are you from North or South Korea?',\n",
    "       'They\\'re so pretty for a black person',\n",
    "       'Scientifically speaking, whites are superior to blacks',\n",
    "       'Filipinos, Mexicans, they\\'re all the same!',\n",
    "       'I bet I know Japanese better than you lol',\n",
    "       'You\\re such a banana',\n",
    "       'You don\\'t act black at all, in fact I just think of you as white!',\n",
    "       'Go find a god damned job and learn to speak English or I\\'ll blind you with a piece of dental floss, you slanty-eyed mother fucker',\n",
    "        'Y\\'all are like the good kind of black people!',\n",
    "       'That Jew belongs in an oven.',\n",
    "        'She needs to get her Jap ass out.',\n",
    "       'I love you so much, you\\'re so cool!!!',\n",
    "       'She\\'s such a hard worker, and I really appreciate that.',\n",
    "       'The state of this nation is a travesty and something needs to change.',\n",
    "       'Obama was the greatest president this country has seen.',\n",
    "       'Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.',\n",
    "       'I\\'d like a nice bowl of ramen to hit the spot right now!',\n",
    "       'Capitalism is an unsustainable and unjust idea, and we need to make changes before global warming destroys the world.',\n",
    "       'The cutest member of BTS has to be V, but if we\\'re going off sense of humor, Jin. However, if we\\'re considering intellect, RM. Not that you asked but the best dancer is JHOPE and the guy I can\\'t believe is my age is Jungkook.',\n",
    "       'For people who have red-green colorblindness, the colors red and green look exactly the same.',\n",
    "       'We hope to see you again!']\n",
    "\n",
    "#labels\n",
    "labels = np.array([1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Conv1D\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "max_features = 5000\n",
    "max_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   tweet  label\n",
      "0      !!! RT @mayasolovely: As a woman you shouldn't...      0\n",
      "1      RT @theChefBoyRD: @victoriaaa_lee @anniespring...      1\n",
      "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...      0\n",
      "3                                @SexWith_SocksOn faggot      1\n",
      "4      @karmendanielle_ u gotta slow down these coon ...      1\n",
      "5      !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...      0\n",
      "6                          @ViewFromBoxSeat She's a cunt      1\n",
      "7      !!!!&#8220;@selfiequeenbri: cause I'm tired of...      0\n",
      "8      \"@ashlingwilde: @ItsNotAdam is bored supposed ...      1\n",
      "9      &#8220;@Crowdifornia: We agree... do you? http...      1\n",
      "10     \" Keeks is a bitch she curves everyone \" lol I...      0\n",
      "11     Happy Columbus Day! Even #BillMaher likes #coc...      1\n",
      "12     @DavetheBrave1 that hoe on some other shit bro...      1\n",
      "13            RT @PeterpandaCat: @savanigga Sav is a fag      1\n",
      "14                               \" bitch get up off me \"      0\n",
      "15                  @FreddyAmazin ratchet looking nigger      1\n",
      "16                                \" bitch plz whatever \"      0\n",
      "17     Why are some people such faggots? Like were yo...      1\n",
      "18                    \" bitches get cut off everyday B \"      0\n",
      "19                    \" black bottle &amp; a bad bitch \"      0\n",
      "20     @marylene58 @sunflower1790 @shelliecorreia @Ja...      1\n",
      "21                       \" cancel that bitch like Nino \"      0\n",
      "22               \" cant you see these hoes wont change \"      0\n",
      "23     RT @TheAfricanSiren: Automatically suspicious ...      1\n",
      "24     RT @salomanizor: Too many faggots on here that...      1\n",
      "25        \" her pussy lips like Heaven doors \" &#128524;      0\n",
      "26                          \" hoe what its hitting for \"      0\n",
      "27     \" i met that pussy on Ocean Dr . i gave that p...      0\n",
      "28        \" i need a trippy bitch who fuck on Hennessy \"      0\n",
      "29                                     You state it gook      1\n",
      "...                                                  ...    ...\n",
      "15832  RT @JoeBudden: Ok, I gotta cut this Carl Thoma...      0\n",
      "15833  RT @JoeBudden: Or the &#8220;I was sleep&#8221...      0\n",
      "15834  RT @JoeBudden: She&#8217;s not a hoe cuz she h...      0\n",
      "15835  RT @JoeBudden: She&#8217;s not a hoe cuz she&#...      0\n",
      "15836  RT @JoeBudden: So the woman I deal with is try...      0\n",
      "15837  RT @JoeBudden: The dating scene so wack out he...      0\n",
      "15838  RT @JoeBudden: These hoes gon FIND a way to we...      0\n",
      "15839  RT @JoeBudden: U famous niggas ruined the game...      0\n",
      "15840  RT @JoeBudden: Women all over America are over...      0\n",
      "15841  RT @JoeBudden: Young, attractive, successful, ...      0\n",
      "15842      RT @JoeCaroselli1: Jameis Winston is a nigger      1\n",
      "15843  RT @JoeCool_TVC: You can't be a hoe saying tha...      0\n",
      "15844  RT @JoeyG_145: Downloaded flappy bird 5 minute...      0\n",
      "15845  RT @JohnBishop100: Top tip of the day - if you...      0\n",
      "15846  RT @JohnnieGoings: Money, clothes, hoes, and c...      0\n",
      "15847  RT @JohnnyFootbalI: Saw some bitch texting and...      0\n",
      "15848  RT @JohnnyFootbalI: Yeah @TigerWoods quit bein...      0\n",
      "15849  RT @JohnnyFootbalI: Yeah Kaepernick might have...      0\n",
      "15850  RT @JohnnyFootbalI: Yeah start me as your flex...      0\n",
      "15851         RT @Johnydeep_: @20ToLife_ bitch nigga lol      0\n",
      "15852  RT @Jojo_51213: What was that you tweeted? I c...      0\n",
      "15853  RT @JoleenDoreen: I was in a Kik group once. B...      0\n",
      "15854  RT @JonHorstHoyer: \"Lester, the parasitic spid...      0\n",
      "15855          RT @JonahAir23: money over the best pussy      0\n",
      "15856  RT @Jonnietherotten: Listen twitter just becau...      0\n",
      "15857  RT @JonnyFcknBlaze: Porn star is fancy talk fo...      0\n",
      "15858   RT @JonnyFootbalI: Fuck bitches, get touchdowns.      0\n",
      "15859  RT @JonyPrivat: #cheese #crackers #lacking htt...      0\n",
      "15860  RT @Jordiiin_: &#128514;if you can fuck my bit...      0\n",
      "15861  RT @JorgeGones: when a bitch that once curved ...      0\n",
      "\n",
      "[15862 rows x 2 columns]\n",
      "                                                   tweet  label\n",
      "15862          RT @JoseCanseco: I do not have bitch tits      0\n",
      "15863  RT @JosephTheFlyGuy: Crazy girlfriends usually...      0\n",
      "15864  RT @JosephTheFlyGuy: Loyal pussy is best pussy...      0\n",
      "15865  RT @JosephTheFlyGuy: This bitch got a real lif...      0\n",
      "15866  RT @JoshGIII: I be in the pussy like https://t...      0\n",
      "15867  RT @JoshYohe_Trib: I wrote whole game story on...      0\n",
      "15868  RT @Joy_Doe: &#128557;&#128557;&#128557;&#1285...      0\n",
      "15869  RT @JsOnMyTweet: &#8220;@muurdasteven: &#8220;...      0\n",
      "15870  RT @JstKeepScrollin: Been trash \"@WeAre_XCI: T...      0\n",
      "15871  RT @JstKeepScrollin: Me fixing my car :10,000\\...      0\n",
      "15872  RT @JuanNDaCut: Explaining to a girl how u don...      0\n",
      "15873  RT @JuanNDaCut: Porn ads be convincing af...\"c...      0\n",
      "15874  RT @JuanNDaCut: When twitter rappers dm me the...      0\n",
      "15875  RT @Juanitaap_: Lorde 17 with a Grammy &amp; b...      0\n",
      "15876  RT @JudahWorldChamp: To help eliminate faking ...      0\n",
      "15877  RT @JudgmentalGay: Best friend being a hoe: ya...      0\n",
      "15878  RT @Juicccyray: &#8220;@1stBlocJeremiah: Broke...      0\n",
      "15879  RT @Juicedballs: Not scared to pepper spray a ...      0\n",
      "15880  RT @Juicy_Squeaky: Any bitch who need a crowd ...      1\n",
      "15881  RT @Jukeyxo: If a girl sit on your face, and y...      0\n",
      "15882  RT @JulieSnark: I love asking really hot, skin...      0\n",
      "15883  RT @Julio_isUrdaddy: She need a man, not no pu...      0\n",
      "15884  RT @JusDontBlowMyHi: Y'all lucky DMX stopped m...      0\n",
      "15885  RT @JusGuapo: These hoes lying and olivia will...      0\n",
      "15886  RT @JusTawana_: &#8220;@Gvmby: This bitch poss...      0\n",
      "15887  RT @Just2Savage: This height shit aint cute at...      0\n",
      "15888  RT @JustAn0th3r: It ain't nuttin to cut that b...      0\n",
      "15889  RT @JustCurrieOn: @west2quick @Christooshifty ...      0\n",
      "15890  RT @JustDoItSlow: @vintage_monroe_ scary told ...      0\n",
      "15891  RT @JustDoIt_Rob: @Kaaarlizzy bitches love my ...      0\n",
      "...                                                  ...    ...\n",
      "20788                                      Shit is trash      0\n",
      "20789   Shit that Seth says, \"It's fatter than my cunt.\"      0\n",
      "20790  Shit where the gay bitches at ? Come be witcha...      0\n",
      "20791                         Shittin on all my old hoes      0\n",
      "20792                 Shoot dat nigga n his shordy bitch      0\n",
      "20793                      Shoot dice let yo hoe fade me      0\n",
      "20794  Shoot out wit yo niccas you da type to throw d...      0\n",
      "20795  Shoot that nigga &amp; his shorty bitch &#1281...      0\n",
      "20796             Shoot that nigga an his shorty bitch .      1\n",
      "20797                    Shoot you and your shorty bitch      0\n",
      "20798  Short answer: Yes. ~ Sage Grouse Rebellion: Wi...      0\n",
      "20799  Shot out to my main bitches and my side bitche...      0\n",
      "20800  Should #Oscar go to @AndySerkis or #Computer t...      0\n",
      "20801  Should I be worried that a lady behind my buil...      0\n",
      "20802  Should I expect good pussy or good but not goo...      0\n",
      "20803  Should I take a nap though too kill a mocking ...      0\n",
      "20804    Should I tell this hoe who she look like cdfuuu      0\n",
      "20805          Shoulda put retard mikey on AHS freakshow      0\n",
      "20806  Shouldn't be liVing* RT @youngtravo: stank pus...      0\n",
      "20807  Shout out to babes @Anastacia_Cole! Love that ...      0\n",
      "20808  Shout out to everyone that puts up with my ret...      0\n",
      "20809  Shout out to you ungrateful, inconsiderate bit...      0\n",
      "20810  ShoutOut to Brooklyn and this $3.47/gal gas. O...      0\n",
      "20811                           Shoutout that real bitch      0\n",
      "20812  Shoutout to my Mamma cause she Ain't Raise no hoe      0\n",
      "20813  Shoutout to this bitch for unfollowing me like...      0\n",
      "20814  Shoutouts to my main bitches &amp; my side bit...      0\n",
      "20815                  Shouts out to all my goth bitches      0\n",
      "20816  Shouts out to my down ass bitches who never gi...      0\n",
      "20817  Show last night was badass thanks to everyone ...      0\n",
      "\n",
      "[4956 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#split the data into train, test, and validation sets\n",
    "data = pd.read_csv('dennisFiles/data/duplicated_modified_davidson_data.csv', names = ['tweet', 'label'])\n",
    "train_portion = data.shape[0]*0.64\n",
    "test_portion = train_portion + data.shape[0]*0.2\n",
    "\n",
    "train = data.loc[0:train_portion,]\n",
    "test = data.loc[train_portion:test_portion,]\n",
    "valid = data.loc[test_portion:,]\n",
    "\n",
    "#x_train = train.ix[0:train_portion,0].values\n",
    "#y_train = train.ix[0:train_portion,1].values\n",
    "\n",
    "#x_test = train.ix[train_portion:test_portion, 0].values\n",
    "#y_test = train.ix[train_portion:test_portion, 1].values\n",
    "\n",
    "#x_valid = train.ix[test_portion:,0].values\n",
    "#y_valid = train.ix[test_portion:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode and pad\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(train['tweet'])\n",
    "\n",
    "#encoded_train = [one_hot(word, max_features) for word in train]\n",
    "#padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "sequences = tokenizer.texts_to_sequences(train['tweet'])\n",
    "train_data = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing class weights\n",
    "#class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\n",
    "#class_weights = {0: 1.,\n",
    "                 #1: 40.}\n",
    "\n",
    "#glove embeddings\n",
    "embeddings_index = dict()\n",
    "f = open('../Glove-1.2/vocab.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((max_features, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index > max_features - 1:\n",
    "        break\n",
    "    else:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=100, weights=[embedding_matrix]))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "15862/15862 [==============================] - 8s 497us/step - loss: 0.4345 - acc: 0.8118\n",
      "Epoch 2/15\n",
      "15862/15862 [==============================] - 6s 374us/step - loss: 0.3593 - acc: 0.8560\n",
      "Epoch 3/15\n",
      "15862/15862 [==============================] - 6s 363us/step - loss: 0.3478 - acc: 0.8577\n",
      "Epoch 4/15\n",
      "15862/15862 [==============================] - 6s 356us/step - loss: 0.3486 - acc: 0.8578\n",
      "Epoch 5/15\n",
      "15862/15862 [==============================] - 6s 367us/step - loss: 0.5212 - acc: 0.7904\n",
      "Epoch 6/15\n",
      "15862/15862 [==============================] - 6s 368us/step - loss: 0.3410 - acc: 0.8613\n",
      "Epoch 7/15\n",
      "15862/15862 [==============================] - 6s 384us/step - loss: 0.3383 - acc: 0.8624\n",
      "Epoch 8/15\n",
      "15862/15862 [==============================] - 6s 384us/step - loss: 0.3416 - acc: 0.8585\n",
      "Epoch 9/15\n",
      "15862/15862 [==============================] - 6s 391us/step - loss: 0.3569 - acc: 0.8548\n",
      "Epoch 10/15\n",
      "15862/15862 [==============================] - 6s 369us/step - loss: 0.3139 - acc: 0.8728\n",
      "Epoch 11/15\n",
      "15862/15862 [==============================] - 6s 387us/step - loss: 0.3276 - acc: 0.8631\n",
      "Epoch 12/15\n",
      "15862/15862 [==============================] - 6s 398us/step - loss: 0.3263 - acc: 0.8667\n",
      "Epoch 13/15\n",
      "15862/15862 [==============================] - 6s 386us/step - loss: 0.3192 - acc: 0.8687\n",
      "Epoch 14/15\n",
      "15862/15862 [==============================] - 6s 385us/step - loss: 0.3198 - acc: 0.8720\n",
      "Epoch 15/15\n",
      "15862/15862 [==============================] - 6s 389us/step - loss: 0.3168 - acc: 0.8669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a20051438>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compile\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fit\n",
    "model.fit(train_data, train['label'], batch_size=2048, epochs=15)\n",
    "#score = model.evaluate(padded_test, y_test, batch_size=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.94      0.96      4764\n",
      "          1       0.25      0.51      0.34       192\n",
      "\n",
      "avg / total       0.95      0.92      0.94      4956\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test = pd.read_csv('dennisFiles/data/expert_labeled_tweets_duplicate.csv')\n",
    "\n",
    "#x_test = test.ix[:, 0].values\n",
    "#y_test = test.ix[:, 1].values\n",
    "\n",
    "#encoded_test = t.texts_to_matrix(x_test, mode='count')\n",
    "#encoded_test = [hashing_trick(word, len(text_to_word_sequence(word))*1.3, hash_function='md5') for word in x_test]\n",
    "sequences = tokenizer.texts_to_sequences(test['tweet'])\n",
    "test_data = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "pred = [1 if element >= 0.5 else 0 for element in model.predict(test_data)]\n",
    "print(classification_report(test['label'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
